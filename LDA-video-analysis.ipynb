{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('ytvideo.csv', header=None)\n",
    "data.columns = ['video_title']\n",
    "data['index'] = data.index\n",
    "documents = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /afs/crc.nd.edu/user/y/ywu6/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english')\n",
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) >= 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original document: \n",
      "['The', 'perfect', 'ice', '-', 'Ice', 'boats', 'on', 'Lake', 'Geneva']\n",
      "\n",
      "\n",
      " tokenized and lemmatized document: \n",
      "['perfect', 'ice', 'ice', 'boat', 'lake', 'geneva']\n"
     ]
    }
   ],
   "source": [
    "doc_sample = documents[documents['index'] == 250].values[0][0]\n",
    "print('original document: ')\n",
    "words = []\n",
    "for word in doc_sample.split(' '):\n",
    "    words.append(word)\n",
    "print(words)\n",
    "print('\\n\\n tokenized and lemmatized document: ')\n",
    "print(preprocess(doc_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_docs = documents['video_title'].map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                [want, talk, marriag]\n",
       "1      [trump, presid, week, tonight, john, oliv, hbo]\n",
       "2    [racist, superman, rudi, mancuso, king, bach, ...\n",
       "3                      [nickelback, lyric, real, fake]\n",
       "4                                     [dare, go, bald]\n",
       "5                                        [week, iphon]\n",
       "6          [roy, moor, jeff, session, cold, open, snl]\n",
       "7                           [ice, cream, gadget, test]\n",
       "8    [greatest, showman, offici, trailer, centuri, ...\n",
       "9                 [rise, robot, won√¢, mean, end, work]\n",
       "Name: video_title, dtype: object"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 768 (\"airlin\") appears 1 time.\n",
      "Word 769 (\"brent\") appears 1 time.\n",
      "Word 770 (\"fli\") appears 1 time.\n",
      "Word 771 (\"pella\") appears 1 time.\n",
      "Word 772 (\"shouldn\") appears 1 time.\n",
      "Word 773 (\"spirit\") appears 1 time.\n"
     ]
    }
   ],
   "source": [
    "bow_doc_200 = bow_corpus[200]\n",
    "\n",
    "for i in range(len(bow_doc_200)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_200[i][0], \n",
    "                                                     dictionary[bow_doc_200[i][0]], \n",
    "                                                     bow_doc_200[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.6385308231954088), (1, 0.4296007165482703), (2, 0.6385308231954088)]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
